\newcommand{\reprueba}{X}
\newcommand{\recursa}{R}
\newcommand{\falta}{F}

\newcommand{\predReprueba}{\textrm{reprueba}}
\newcommand{\predRecursa}{\textrm{recursa}}
\newcommand{\predFalta}{\textrm{falta}}
\newcommand{\funFinal}{\textrm{final}}

\newcommand{\vAlu}{a}
\newcommand{\vMat}{m}
\newcommand{\vEx}{e}

\newcommand{\proofSpacing}{\vspace*{0.2cm}}

% \begin{itemize}
%     \item Ejemplo de demostración en lenguaje natural \ok
%     \item Necesitamos una forma estructural de representar demostraciones \ok
%     \item Proof calculus / proof system enmarcado en Proof theory. Cómo están
%     compuestos en general \ok
%     \item Natural deduction \ok
%     \item Reglas de introducción y eliminación \ok
%     \item Formalización del ejemplo \ok
%     \item Ejemplo con cuantificadores \ok
%     \item Cut como meta-teorema (y meta teoremas en general) \ok
%     \item Implementación de data types principales \ok
%     \item Algoritmo de chequeo \ok
%     \item Algoritmos adicionales: alpha igualdad, variables libres, sust sin capturas \ok
% \end{itemize}

Vamos a comenzar por las fundaciones: Queremos armar un programa que permita
escribir teoremas y demostraciones. ¿Cómo se representa una demostración en la
computadora? Es necesaria una representación precisa y rigurosa.

En el área de estudio de \textit{proof theory}, en la cuál las
demostraciones son tratadas como objetos matemáticos formales, nos encontramos
con los \textit{proof calculi} o \textit{proof systems}, que son sistemas
lógicos formales que permiten demostrar sentencias. Pueden ser modelados como un
tipo abstracto de datos, así siendo representados en la computadora.

Por ejemplo, supongamos que tenemos la siguiente \textit{teoría} de exámenes en
la facultad, que vamos a ir iterando a lo largo de la tesis. Por ahora, en su
versión proposicional. Si un alumno reprueba un final, entonces recursa. Si un
alumno falta, entonces reprueba. Con estas dos, podríamos demostrar que si un
alumno falta a un final, entonces recursa. Veamos cómo podría ser una
demostración en lenguaje natural.

\begin{ejemplo}\label{nd:ex:exam}
    Si ((reprueba entonces recursa) y (falta entonces reprueba)) y falta, entonces recursa.

    Demostración:
\begin{itemize}
    \item Asumo que falta. Quiero ver que recursa.
    \item Sabemos que si falta, entonces reprueba. Reprobó.
    \item Sabemos que si reprueba, entonces recursa.
    \item $\therefore$ recursó.
\end{itemize}
    \qed
\end{ejemplo}

¿Cómo podría ser formalizada en un \textit{proof system}?

\section{El sistema de deducción natural}

Los \textit{proof systems} en general están compuestos por

\begin{itemize}
    \item \textbf{Lenguaje formal}: el conjunto $L$ de fórmulas admitidas por
    el sistema. En nuestro caso, lógica de primer orden.
    \item \textbf{Reglas de inferencia}: lista de reglas que se usan para probar
    teoremas de axiomas y otros teoremas. Por ejemplo, \textit{modus ponens} (si
    es cierto $\form \fImp \formTwo$ y $\form$, se puede concluir $\formTwo$) o
    \textit{modus tollens} (si es cierto $\form \fImp \formTwo$ y $\fNot
    \formTwo$, se puede concluir $\fNot\form$)
    \item \textbf{Axiomas}: fórmulas de $L$ que se asumen válidas. Todos los
    teoremas se derivan de axiomas. Por ejemplo, como estamos en lógica clásica,
    vale el axioma \textit{LEM} (Law of Excluded Middle): $\form \vee \fNot \form$
\end{itemize}

El sistema particular que usamos se conoce como \textbf{deducción natural},
introducido por Gerhard Gentzen en \cite{gentzen-1935} \todo{Chequear cita}.
Tiene dos tipos de \textit{reglas de inferencia} para cada operador ($\wedge$,
$\vee$, $\exists$, $\dots$), que nos permiten razonar

\begin{itemize}
    \item \textbf{Introducción}: ¿Cómo demuestro este operador?
    \item \textbf{Eliminación}: ¿Cómo uso este operador para demostrar otra fórmula?
\end{itemize}

Introducimos algunas definiciones preliminares, luego vemos las reglas de inferencia, un ejemplo de una demostración, y finalmente explicamos cada regla.

\begin{definition}{Contexto de demostración.}
    \begin{itemize}
        \item Definimos los \textbf{contextos de demostración} $\ctx$ como un conjunto de fórmulas, compuesto por las hipótesis que se asumen a lo largo de una demostración.
        \item Para algunas reglas es necesario conocer las variables libres de un contexto, que se definen de la forma usual:
        
        \[
            \fv{\ctx} = \bigcup_{\form \in \ctx} \fv{\form}
        \]
    \end{itemize}
\end{definition}

\begin{definition}{Relación $\judG$.}
    Las reglas de inferencia de la \namedref{nd:inference-rules} definen la siguiente relación, que intuitivamente puede ser interpretada como ``$\form$ es una consecuencia de las suposiciones de $\ctx$''

    \[ \ctx \judG \form \]
\end{definition}

\begin{definition}{Sustitución.}
    Notamos la \textbf{sustitución sin capturas} de todas las ocurrencias libres de la variable $\var$ por el término $\term$ en la fórmula $\form$ como

    \[
        \form \subst{\var}{\term}
    \]

    Se explora en más detalle en la \fullref{nd:sec:subst}
\end{definition}

\subsection{Reglas de inferencia}

\begin{figure}[H]
    \begin{multicols}{2}
        \proofTreeFalseE
        \proofTreeTrueI
    \end{multicols}
    
    \begin{multicols}{2}
        \proofTreeLEM
        \proofTreeAx
    \end{multicols}

    \proofSpacing

    \proofTreeAndI

    \begin{multicols}{2}
        \proofTreeAndEOne
        \proofTreeAndETwo
    \end{multicols}

    \proofSpacing

    \begin{multicols}{2}
        \proofTreeOrIOne
        \proofTreeOrITwo
    \end{multicols}
    
    \proofTreeOrE

    \proofSpacing

    \begin{multicols}{2}
        \proofTreeImpI
        \proofTreeImpE
    \end{multicols}
    \begin{multicols}{2}
        \proofTreeNotI
        \proofTreeNotE
    \end{multicols}

    \proofSpacing

    \begin{multicols}{2}
        \proofTreeForallI
        \proofTreeForallE
    \end{multicols}

    \proofSpacing

    \proofTreeExistsI
    \proofTreeExistsE

    \caption{Reglas de inferencia para deducción natural de lógica de primer orden}
    \label{nd:inference-rules}
\end{figure}

\subsection{Ejemplo introductorio}

\begin{ejemplo}\label{nd:ex:exam-nd}
    Demostración de \fullref{nd:ex:exam} en deducción natural. Como es en su
    versión proposicional, vamos a modelarlo para un solo alumno y materia. Notamos
    \begin{itemize}
        \item $\reprueba \equiv \predReprueba(juan, \funFinal(logica))$
        \item $\recursa \equiv \predRecursa(juan, logica)$
        \item $\falta \equiv \predFalta(juan, \funFinal(logica))$
    \end{itemize}

    Queremos probar entonces 
    \[
        \Big(
            (\reprueba \fImp \recursa) \wedge (\falta \fImp \reprueba)
        \Big)
        \fImp
        (\falta \fImp \recursa)
    \]

    \begin{figure}[H]
        \begin{prooftree}
            \AxiomC{}
            \RL{\ruleAx}
            \UnaryInfC{$\ctx \judG (\reprueba \fImp \recursa) \wedge (\falta \fImp \reprueba)$}
            \RL{\ruleAndEOne}
            \UnaryInfC{$\ctx \judG \reprueba \fImp \recursa$}
    
            \AxiomC{}
            \RL{\ruleAx}
            \UnaryInfC{$\ctx \judG (\reprueba \fImp \recursa) \wedge (\falta \fImp \reprueba)$}
            \RL{\ruleAndETwo}
            \UnaryInfC{$\ctx \judG \falta \fImp \reprueba$}
            \AxiomC{}
            \RL{\ruleAx}
            \UnaryInfC{$\ctx \judG \falta$}
            \RL{\ruleImpE}
            \BinaryInfC{$\ctx \judG \reprueba$}
            \RL{\ruleImpE}
            \BinaryInfC{\(
                \ctx =
                (\reprueba \fImp \recursa) \wedge (\falta \fImp \reprueba),\
                \falta
                \judG
                \recursa
            \)}
            \RL{\ruleImpI}
            \UnaryInfC{\(
                (\reprueba \fImp \recursa) \wedge (\falta \fImp \reprueba)
                \judG
                \falta \fImp \recursa 
            \)}
            \RL{\ruleImpI}
            \UnaryInfC{\(
                \judG
                \Big(
                    (\reprueba \fImp \recursa) \wedge (\falta \fImp \reprueba)
                \Big)
                \fImp
                (\falta \fImp \recursa)
            \)}
        \end{prooftree}
    
        \caption{Demostración de \(
        \big(
            (\reprueba \fImp \recursa) \wedge (\falta \fImp \reprueba)
        \big)
        \fImp
        (\falta \fImp \recursa)
    \) en deducción natural}
        \label{nd:fig:proof-exam-nd}
    \end{figure}

    Las demostraciones en deducción natural son un árbol, en el que cada juicio está justificado por una regla de inferencia, que puede tener sub-árboles de demostración. La raíz es la fórmula a demostrar. Paso por paso,

    \begin{itemize}
        \item \ruleImpI: \textit{introducimos} la implicación. Para demostrarla,
        asumimos el antecedente y en base a eso demostramos el consecuente. Es
        decir asumimos $(\reprueba \fImp \recursa) \wedge (\falta \fImp
        \reprueba)$, y en base a eso queremos deducir $\falta \fImp \recursa$.
        \item \ruleImpI: Asumimos $\falta$, nos queda probar $\recursa$.
        Renombramos el \textit{contexto} de hipótesis como $\ctx$.
        \item La estrategia para probar $\recursa$ es usando la siguiente cadena
        de implicaciones: $\falta \fImp \reprueba \fImp \recursa$, y sabemos que
        vale $\falta$. Como tenemos que probar $\recursa$, arrancamos de atrás para
        adelante.
        \item \ruleImpE: \textit{eliminamos} una implicación, la usamos para
        deducir su conclusión demostrando el antecedente. Esta regla de
        inferencia tiene dos partes, probar la implicación ($\reprueba \fImp
        \recursa$), y probar el antecedente ($\reprueba$).
        \begin{itemize}
            \item Para probar la implicación, tenemos que usar la hipótesis \textit{eliminando} la conjunción y especificando cuál
            de las dos cláusulas estamos usando.
            \item Para probar el antecedente $\reprueba$, es un proceso análogo
            pero usando la otra implicación y el hecho de que vale $\falta$ por hipótesis.
        \end{itemize}
        \item Las hojas del árbol, los casos base, suelen ser aplicaciones de
        la regla de inferencia \ruleAx, que permite deducir fórmulas citando
        hipótesis del contexto.
    \end{itemize}
\end{ejemplo}

\section{Intuición detrás de las reglas}

A continuación se explican brevemente las reglas de inferencia listadas en \namedref{nd:inference-rules}.

\subsection{Reglas base}

\begin{multicols}{2}
    \proofTreeFalseE
    \proofTreeTrueI
\end{multicols}

\begin{multicols}{2}
    \proofTreeLEM
    \proofTreeAx
\end{multicols}

\begin{itemize}
    \item \ruleFalseE: A partir de $\fFalse$, algo que es falso, vamos a poder deducir cualquier
    fórmula.
    \item \ruleTrueI: $\fTrue$ trivialmente vale siempre
    \item \ruleLEM: El \textit{principio del tercero excluido} que vale en
    lógica clásica. Incluir este axioma es lo que hace que este sistema sea
    clásico.
    \item \ruleAx: Como ya vimos en el \fullref{nd:ex:exam-nd}, lo usamos para
    deducir fórmulas que ya tenemos como hipótesis.
\end{itemize}

\subsection{Reglas de conjunciones y disyunciones}

\proofTreeAndI

\begin{multicols}{2}
    \proofTreeAndEOne
    \proofTreeAndETwo
\end{multicols}

\begin{multicols}{2}
    \proofTreeOrIOne
    \proofTreeOrITwo
\end{multicols}

\proofTreeOrE

\begin{itemize}
    \item \ruleAndI: Para demostrar una conjunción, debemos demostrar ambas fórmulas.
    \item \ruleAndEOne / \ruleAndETwo: A partir de una conjunción podemos
    deducir cualquiera de las dos fórmulas que la componen, porque ambas valen.
    Se modela con dos reglas.
    \item \ruleOrIOne / \ruleOrITwo: Para demostrar una disyunción, alcanza con
    demostrar una de sus dos fórmulas. Se modela con dos reglas al igual que la
    eliminación de conjunción.
    \item \ruleOrE: Nos permite deducir una conclusión a partir de una
    disyunción dando sub demostraciones que muestran que sin importar cual de
    las dos valga, asumiéndolas por separado, se puede demostrar.
\end{itemize}

\subsection{Reglas de implicación y negación}

\begin{multicols}{2}
    \proofTreeImpI
    \proofTreeImpE
\end{multicols}

\proofSpacing

\begin{multicols}{2}
    \proofTreeNotI
    \proofTreeNotE
\end{multicols}

\begin{itemize}
    \item \ruleImpI: Para demostrar una implicación, asumimos el antecedente
    (agregándolo a las hipótesis) y en base a eso se demuestra el consecuente.
    \item \ruleImpE: también conocida como \textit{modus ponens}. A partir de
    una implicación, si podemos demostrar su antecedente, entonces vale su consecuente.
    \item \ruleNotI: Para demostrar una negación, lo hacemos por el absurdo:
    asumimos que vale la fórmula y llegamos a una contradicción. Esta regla
    también se suele llamar \textit{reducción al absurdo} o RAA.
    \item \ruleNotE: Podemos concluir un absurdo demostrando que vale una
    fórmula y su negación.
\end{itemize}

\subsection{Reglas de cuantificadores}

Las reglas de $\forall$ y $\exists$ se pueden ver como extensiones a las de
$\wedge$ y $\vee$. Un $\forall$ se puede pensar como una conjunción con un
elemento por cada uno del dominio sobre el cual se cuantifica, y análogamente un $\exists$ como una disyunción.

\begin{multicols}{2}
    \proofTreeForallI
    \proofTreeForallE
\end{multicols}

\begin{itemize}
    \item \ruleForallI: Para demostrar un $\forall \var. \form$, quiero ver que sin importar el valor que tome $\var$ yo puedo demostrar $\form$. Pero para eso en el contexto $\ctx$ no tengo que tenerlo ligado a nada, sino no lo estaría demostrando en general.
    \item \ruleForallE: Para usar un $\forall \var.\form$ para demostrar, como
    vale para todo $\var$, puedo instanciarlo en \textit{cualquier término} $\term$.
\end{itemize}

\proofTreeExistsI
\proofTreeExistsE

\begin{itemize}
    \item \ruleExistsI: Para demostrar un $\exists$, alcanza con instanciar $\var$ en un término $\term$ para el que sea cierto.
    \item \ruleExistsE: Para usar un $\exists$ para demostrar, es parecido a \ruleE{$\vee$}. Como tenemos que ver que vale para cualquier $\var$, podemos concluir $\formTwo$ tomando como hipótesis $\form$ con $\var$ sin instanciar. 
\end{itemize}

\begin{ejemplo}
    \label{nd:ex:exam-nd-lpo}
    Para ejemplificar el uso de las reglas de cuantificadores, extendemos el \namedref{nd:ex:exam-nd} a primer orden. Usamos

    \begin{itemize}
        \item $\vAlu$ representa un alumno, $\vMat$ una materia y $\vEx$ un examen.
        \item $\reprueba(\vAlu, \vEx) \equiv \predReprueba(\vAlu, \vEx)$
        \item $\recursa(\vAlu, \vMat) \equiv \predRecursa(\vAlu, \vMat)$
        \item $\falta(\vAlu, \vEx) \equiv \predFalta(\vAlu, \vEx)$
    \end{itemize}

    Vamos a tomar los siguientes como \textit{axiomas}, que van a formar parte del contexto inicial de la demostración. Es lo mismo que haremos en PPA para modelar teorías de primer orden.

    \begin{itemize}
        \item Si un alumno reprueba el final de una materia, entonces recursa
        \[
            \forall \vAlu .\ \forall \vMat .\
                (\reprueba(\vAlu, \funFinal(\vMat)) \fImp
                \recursa(\vAlu, \vMat))
        \]
        \item Si un alumno falta a un examen, lo reprueba
        \[
            \forall \vAlu .\ \forall \vEx .\
                (\falta(\vAlu, \vEx) \fImp \reprueba(\vAlu, \vEx))
        \]
    \end{itemize}

    Definimos

    \[
        \ctx_0 = \{
            \forall \vAlu .\ \forall \vMat .\
                \reprueba(\vAlu, \funFinal(\vMat)) \fImp
                \recursa(\vAlu, \vMat),
            \forall \vAlu .\ \forall \vEx .\
                \falta(\vAlu, \vEx) \fImp \reprueba(\vAlu, \vEx)
        \}
    \]

    Luego, queremos probar
    \(
        \ctx_0 \judG
            \forall \vAlu .\ \forall \vMat .\
                \falta(\vAlu, \funFinal(\vMat)) \fImp
                \recursa(\vAlu, \vMat)
    \)
    
    \begin{figure}
        \begin{prooftree}
            \AxiomC{}
            \RL{\ruleAx{}}
            \UnaryInfC{\(
                \ctx_1 \judG
                    \forall \vAlu \forall \vMat .\ \reprueba(\vAlu, \funFinal(\vMat)) \fImp \recursa(\vAlu, \vMat)
            \)}
            \RL{\ruleForallE{}}
            \UnaryInfC{\(
                \ctx_1 \judG
                    \forall \vMat .\ \reprueba(\vAlu, \funFinal(\vMat)) \fImp \recursa(\vAlu, \vMat)
            \)}
            \RL{\ruleForallE{}}
            \UnaryInfC{\(
                \ctx_1 \judG
                    \reprueba(\vAlu, \funFinal(\vMat)) \fImp \recursa(\vAlu, \vMat)
            \)}
    
            \AxiomC{$\someProof$}
            \noLine
            \UnaryInfC{\(
                \ctx_1 \judG \reprueba(\vAlu, \funFinal(\vMat))
            \)}
            \RL{\ruleImpE{}}
            \BinaryInfC{\(
                \ctx_1 = \ctx_0, \falta(\vAlu, \funFinal(\vMat)) \judG \recursa(\vAlu, \vMat)
            \)}
            \RL{\ruleImpI{}}
            \UnaryInfC{\(\ctx_0 \judG \falta(\vAlu, \funFinal(\vMat)) \fImp
                \recursa(\vAlu, \vMat)\)}
            \RL{\ruleForallI{}}
            \UnaryInfC{\(
                \ctx_0 \judG \forall \vMat .\
                \falta(\vAlu, \funFinal(\vMat)) \fImp
                \recursa(\vAlu, \vMat)
            \)}
            \RL{\ruleForallI{}}
            \UnaryInfC{\(
            \ctx_0 \judG
            \forall \vAlu .\ \forall \vMat .\
                \falta(\vAlu, \funFinal(\vMat)) \fImp
                \recursa(\vAlu, \vMat)
            \)}
        \end{prooftree}

        Con

        \begin{prooftree}
            \AxiomC{}
            \RL{\ruleAx}
            \UnaryInfC{\(
                \ctx_1 \judG
                    \forall \vAlu .\ \forall \vEx .\
                        \falta(\vAlu, \vEx) \fImp \reprueba(\vAlu, \vEx)
            \)}
            \RL{\ruleForallE{}}
            \UnaryInfC{\(
                \ctx_1 \judG
                    \forall \vEx .\
                        \falta(\vAlu, \vEx) \fImp \reprueba(\vAlu, \vEx)
            \)}
            \RL{\ruleForallE{}}
            \UnaryInfC{\(
                \ctx_1 \judG
                    \falta(\vAlu, \funFinal(\vMat)) \fImp \reprueba(\vAlu, \funFinal(\vMat))
            \)}
            \AxiomC{}
            \RL{\ruleAx{}}
            \UnaryInfC{\(
                \ctx_1 \judG \falta(\vAlu, \funFinal(\vMat))
            \)}
            \RL{\ruleImpE{}}
            \LL{$\someProof=$}
            \BinaryInfC{\(
                \ctx_1 \judG \reprueba(\vAlu, \funFinal(\vMat))
            \)}
        \end{prooftree}
        \caption{Demostración con cuantificadores en deducción natural}
    \end{figure}
\end{ejemplo}

\section{Ajustes para generación de demostraciones}

\subsection{Hipótesis etiquetadas}

En las secciones anteriores presentamos a los contextos $\ctx$ como \textit{conjuntos} de fórmulas. Pero en realidad, para mayor claridad en las demostraciones, vamos a querer que las hipótesis estén \textbf{etiquetadas}. Para permitirlo, las diferencias son las siguientes.

\begin{itemize}
    \item Los contextos $\ctx$ son conjuntos de pares $\hypId : \form$ de etiquetas y fórmulas.
    \item Las reglas que hacen uso de hipótesis, lo hacen nombrándolas.
    
    \todo{\ruleExistsE}

    \begin{multicols}{3}
        \begin{prooftree}
            \AxiomC{$\bm{\hypId} : \form \in \ctx$}
            \RL{\ruleAx}
            \UnaryInfC{$\judg{\ctx}{\form}$}
        \end{prooftree}
    
        \begin{prooftree}
            \AxiomC{$\judg{\ctx, \bm{\hypId}: \form}{\formTwo}$}
            \RL{\ruleImpI}
            \UnaryInfC{$\judg{\ctx}{\form \to \formTwo}$}
        \end{prooftree}
    
        \begin{prooftree}
            \AxiomC{$\judg{\ctx, \bm{\hypId}: \form}{\bot}$}
            \RL{\ruleNotI}
            \UnaryInfC{$\judg{\ctx}{\fNot \form}$}
        \end{prooftree}    
    \end{multicols}
\end{itemize}

\duda{No veo por qué con esta presentación sería necesario tener a los nombres de las reglas con las etiquetas, por ej. \ruleImpI$_{\hypId}$}

\subsection{Variables libres en contexto}

Las reglas \ruleForallI{} y \ruleExistsE{} requieren que la variable del cuantificador no esté libre en el contexto. Esto representó un problema en la generación de demostraciones. Por ejemplo cuando se citan otros teoremas y se insertan sus demostraciones, si usan las mismas variables, lo cual es usual, llevaban a conflictos. Para evitar esos problemas, lo cambiamos por algo más permisivo pero que mantiene validez: en lugar de fallar, remueve del contexto todas las hipótesis que contengan libre esa variable en la sub-demostración.

\newcommand{\ctxClean}{\bm{\hat{\ctx}}}

\begin{prooftree}
    \AxiomC{$\judg{\ctxClean}{\form}$}
    \AxiomC{$x \notin \fv{\ctx}$}
    \RL{\ruleForallI}
    \BinaryInfC{$\judg{\ctx}{\forall \var.\form}$}
\end{prooftree}

\begin{prooftree}
    \AxiomC{$\judg{\ctxClean}{\exists \var.\form}$}
    \AxiomC{$\judg{\ctxClean, \form}{\formTwo}$}
    \AxiomC{$x \notin \fv{\formTwo}$}
    \RL{\ruleExistsE}
    \TrinaryInfC{$\judg{\ctx}{\formTwo}$}
\end{prooftree}

donde

\[
    \ctxClean = \{ \form \in \ctx \mid \var \notin \fv{\form} \}
\]

\section{Reglas admisibles}\label{nd:sec:admissible-rules}

Antes mencionamos \textit{modus tollens} como regla de inferencia, pero no aparece en la \namedref{nd:inference-rules}. Esto es porque nos va a interesar tener un sistema
lógico minimal: no vamos a agregar reglas de inferencia que se puedan deducir a
partir de otras, es decir, \textit{reglas admisibles}. Nos va a servir para
simplificar el resto de PPA, dado que vamos a generar demostraciones en
deducción natural y operar sobre ellas. Mientras más sencillas sean las partes con las que se componen, mejor. Las reglas admisibles las podemos demostrar para cualquier fórmula, así luego podemos usarlas como \textit{macros}.

\begin{ejemplo}{\textit{Modus tollens}}
    
    \begin{prooftree}
        \AxiomC{}
        \RL{\ruleAx}
        \UnaryInfC{\(\ctx \judG (\form \fImp \formTwo) \fAnd \fNot \formTwo\)}
        \RL{\ruleAndETwo}
        \UnaryInfC{\(
            \ctx \judG \fNot \formTwo
        \)}
        \AxiomC{}
        \RL{\ruleAx}
        \UnaryInfC{\(\ctx \judG (\form \fImp \formTwo) \fAnd \fNot \formTwo\)}
        \RL{\ruleAndEOne}
        \UnaryInfC{$\ctx \judG \form \fImp \formTwo$}
        \AxiomC{}
        \RL{\ruleAx}
        \UnaryInfC{$\ctx \judG \form$}
        \RL{\ruleImpE}
        \BinaryInfC{\(
            \ctx \judG \formTwo
        \)}
        \RL{\ruleNotE{}}
        \BinaryInfC{\(
            \ctx = (\form \fImp \formTwo) \fAnd \fNot \formTwo, \form
            \judG
            \fFalse
        \)}
        \RL{\ruleNotI{}}
        \UnaryInfC{\(
            (\form \fImp \formTwo) \fAnd \fNot \formTwo
            \judG
            \fNot \form
        \)}
        \RL{\ruleImpI{}}
        \UnaryInfC{\(\judG
            (\form \fImp \formTwo \fAnd \fNot \formTwo)
            \fImp \fNot\form
        \)}
    \end{prooftree}
\end{ejemplo}

\nota{cut y dnegElim las voy a contar en la sección del certifier, que es donde se usan.}

\section{Algoritmos}

A continuación describimos los algoritmos que son necesarios para la implementación de deducción natural. El chequeo de las demostraciones, alpha equivalencia de fórmulas, sustitución sin capturas, y variables libres

\subsection{Chequeador}
\label{nd:sec:checker}
\diffNew{Sección reescrita!}

El algoritmo de chequeo de una demostración en deducción natural consiste en recorrer recursivamente el árbol de demostración, chequeando que todas las inferencias sean válidas y manteniendo un contexto $\ctx$ en el camino.
Se chequea Que se usan para demostrar la fórmula que corresponde (no un \ruleAndI{} para un $\fOr$) y que cumplen con las condiciones impuestas.

El módulo que se encarga de implementarlo es el \modChecker, su función principal es

\begin{minted}{haskell}
    check :: Env -> Proof -> Form
\end{minted}


donde \mintinline{haskell}{Env} es el contexto $\ctx$, \mintinline{haskell}{Proof} es el término de demostración en deducción natural y \mintinline{haskell}{Form} es la fórmula que demuestra.

\subsection{Alpha equivalencia}

Si tenemos una hipótesis $\exists \var . \fun(\var)$, sería ideal poder usarla para demostrar a partir de ella una fórmula $\exists \varTwo . \fun(\varTwo)$. Si bien no son exactamente iguales, son \textbf{alpha-equivalentes}: su estructura es la misma, pero tienen nombres diferentes para variables \textit{ligadas} (no libres)

\begin{definition}{Alpha equivalencia}. Se define la relación $\alphaEq$ como la que permite renombrar variables ligadas evitando capturas. Es la congruencia más chica que cumple con
\begin{align*}
    (\forall \var . \form) \alphaEq (\forall \varTwo . \form')
        &\iff
        \form \subst{\var}{\varThree} \alphaEq
        \form' \subst{\varTwo}{\varThree} \text{ con $\varThree$ fresca}
        \\
    (\exists \var . \form) \alphaEq (\exists \varTwo . \form')
        &\iff
        \form \subst{\var}{\varThree} \alphaEq
        \form' \subst{\varTwo}{\varThree} \text{ con $\varThree$ fresca}
        \\
\end{align*}

\end{definition}

Para implementarlo, un algoritmo naïve podría ser cuadrático: chequeamos recursivamente la igualdad estructural de ambas fórmulas. Si nos encontramos con un cuantificador con variables con nombres distintos, digamos $\var$ e $\varTwo$, elegimos una nueva variable \textit{fresca} (para evitar capturas) y lo renombramos recursivamente en ambos. Luego continuamos con el algoritmo. Si en la base nos encontramos con dos variables, tienen que ser iguales.

Para hacerlo un poco más eficiente, se implementó un algoritmo lineal en la estructura de la fórmula. Mantenemos dos sustituciones de variables, una para cada fórmula. Si nos encontramos con $\exists \var . \fun(\var)$ y $\exists \varTwo . \fun(\varTwo)$, vamos a elegir una variable fresca igual que antes (por ejemplo $\varThree$), pero en vez de renombrar recursivamente, que lo hace cuadrático, insertamos en cada sustitución los renombres $\var \mapsto \varThree$ y $\varTwo \mapsto \varThree$. Luego, cuando estemos comparando dos variables libres, chequeamos que \textit{sus renombres} sean iguales. En este ejemplo son alpha equivalentes, pues

\begin{align*}
    (\exists \var . \fun(\var)) \alphaEq (\exists \varTwo . \fun(\varTwo))
    &\iff \fun(\var) \alphaEq \fun(\varTwo)
        &&\{\var \mapsto \varThree\}, \{\varTwo \mapsto \varThree\}\\
    &\iff \var \alphaEq \varTwo
        &&\{\var \mapsto \varThree\}, \{\varTwo \mapsto \varThree\}\\
    &\iff \varThree = \varThree.
\end{align*}

\subsection{Sustitución sin capturas}\label{nd:sec:subst}

Notamos la sustitución de todas las ocurrencias libres de la variable $\var$ por un término $\term$ en una fórmula $\form$ como
\(
    \form\subst{\var}{\term}.
\)
Esto se usa en algunas reglas de inferencia,

\proofTreeForallE

Pero queremos evitar \textbf{captura de variables}. Por ejemplo, en

\[
    \forall \varTwo . \pred(\var)\subst{\var}{\varTwo},
\]

si sustituimos sin más, estaríamos involuntariamente ``capturando'' a $\varTwo$. Si hiciéramos que falle, tener que escribir las demostraciones con estos cuidados puede ser muy frágil y propenso a errores, por lo que es deseable que se resuelva \textit{automáticamente}: cuando nos encontramos con una captura, sustituimos la variable ligada de forma que no ocurra.

\[
    \forall \varTwo . \pred(\var)\subst{\var}{\varTwo} =
    \forall \bm{\varThree} . \pred(\varTwo)
\]

donde $\varThree$ es una variable \textit{fresca}.

\begin{definition}{Sustitución sin capturas}. Se define inductivamente en la estructura la fórmula. Sean $\varTwo$ una variable y $\term$ un término cualquiera.
    \begin{itemize}
        \item Términos
        \begin{align*}
            \var\subst{\varTwo}{\term} &= \begin{cases}
                t &\text{si } \var = \varTwo\\
                \var &\text{si no}
            \end{cases}\\
            \fun(\term_1, \dots, \term_n)\subst{\varTwo}{\term} &=
                \fun(
                    \term_1\subst{\varTwo}{\term},
                    \dots,
                    \term_n\subst{\varTwo}{\term}
                )
        \end{align*}

        \item Fórmulas
        \begin{align*}    
            \fFalse\subst{\varTwo}{\term} &= \fFalse\\
            \fTrue\subst{\varTwo}{\term} &= \fTrue\\
            \pred(\term_1, \dots, \term_n)\subst{\varTwo}{\term} &=
            \pred(
                    \term_1\subst{\varTwo}{\term},
                    \dots,
                    \term_n\subst{\varTwo}{\term}
                )
            \\
            (\form \fAnd \formTwo)\subst{\varTwo}{\term} &= 
                \form\subst{\varTwo}{\term} \fAnd \formTwo\subst{\varTwo}{\term}\\
            (\form \fOr \formTwo)\subst{\varTwo}{\term} &=
            \form\subst{\varTwo}{\term} \fOr \formTwo\subst{\varTwo}{\term}\\
            (\form \fImp \formTwo)\subst{\varTwo}{\term} &=
            \form\subst{\varTwo}{\term} \fImp \formTwo\subst{\varTwo}{\term}\\
            (\fNot \form)\subst{\varTwo}{\term} &=
                \fNot \form\subst{\varTwo}{\term}\\
            (\forall \var . \form)\subst{\varTwo}{\term} &=
            \begin{cases}
                \forall \varThree . (A\subst{\var}{\varThree})\subst{\varTwo}{\term}
                    &\text{si } \var = \varTwo, \text{ con } \varThree \text{ fresca}\\
                \forall \var . A\subst{\varTwo}{\term} &\text{si no}
            \end{cases}
            \\
            (\exists \var . \form)\subst{\varTwo}{\term} &=
            \begin{cases}
                \exists \varThree . (A\subst{\var}{\varThree})\subst{\varTwo}{\term}
                    &\text{si } \var = \varTwo, \text{ con } \varThree \text{ fresca}\\
                \exists \var . A\subst{\varTwo}{\term} &\text{si no}
            \end{cases}
        \end{align*}

    \end{itemize}
\end{definition}

Para implementarlo, cada vez que nos encontramos con una captura, vamos a \textit{renombrar} la variable del cuantificador por una nueva, fresca. Al igual que la alpha igualdad, esto se puede implementar de forma naïve cuadrática pero lo hicimos lineal. Mantenemos un único mapeo a lo largo de la sustitución, y cada vez que nos encontramos con una variable libre, si son iguales la sustituimos por el término, y si está mapeada la renombramos.

\subsection{Variables libres}

\duda{Mover a la sección de LPO en la introducción? esto es well-known}

\begin{definition}{Variables libres de fórmulas y términos}. Se definen inductivamente en su estructura de la siguiente forma.

    \begin{itemize}
        \item Términos
        \begin{align*}
            \fv{\var} &= \{ \var \}\\
            \fv{\fun(\term_1, \dots, \term_n)} &= \bigcup_{i \in 1\dots n} \fv{t_i} 
        \end{align*}
    
        \item Fórmulas
        \begin{align*}
            \fv{\fFalse} &=\emptyset\\
            \fv{\fTrue} &=\emptyset \\
            \fv{\pred(\term_1, \dots, \term_n)} &= \bigcup_{i \in 1\dots n} \fv{t_i} \\
            \fv{\form \fAnd \formTwo} &= \fv{\form} \cup \fv{\formTwo}\\
            \fv{\form \fOr \formTwo} &=\fv{\form} \cup \fv{\formTwo}\\
            \fv{\form \fImp \formTwo} &=\fv{\form} \cup \fv{\formTwo}\\
            \fv{\fNot \form} &=\fv{\form}\\
            \fv{\forall \var . \form} &= \fv{\form} \setminus \var \\
            \fv{\exists \var . \form} &= \fv{\form} \setminus \var
        \end{align*}

    \end{itemize}
\end{definition}

\begin{definition}{Variables libres de una demostración.} Sea $\someProof$ una demostración. $\fv{\someProof}$ son las variables libres de todas las fórmulas que la componen. Por ejemplo, para la siguiente

    \proofTreeAndI

    se tiene $\fv{\someProof} = \fv{\form} \cup \fv{\formTwo}$
    
\end{definition}
