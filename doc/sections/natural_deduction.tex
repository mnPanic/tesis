% \begin{itemize}
%     \item Ejemplo de demostración en lenguaje natural \ok
%     \item Necesitamos una forma estructural de representar demostraciones \ok
%     \item Proof calculus / proof system enmarcado en Proof theory. Cómo están
%     compuestos en general \ok
%     \item Natural deduction \ok
%     \item Reglas de introducción y eliminación \ok
%     \item Formalización del ejemplo \ok
%     \item Ejemplo con cuantificadores \ok
%     \item Cut como meta-teorema (y meta teoremas en general) \ok
%     \item Implementación de data types principales \ok
%     \item Algoritmo de chequeo \ok
%     \item Algoritmos adicionales: alfa igualdad, variables libres, sust sin capturas \ok
% \end{itemize}

Comencemos por las fundaciones: queremos armar un programa que permita escribir
teoremas y demostraciones, pero, ¿cómo se representa una demostración en la
computadora? No alcanza con hacerlo de la misma forma que escribimos demostraciones en papel (como en el \namedref{nd:ex:exam}). Debe ser una representación más precisa.

En el área de estudio de \textit{teoría de pruebas}, en la cuál las
demostraciones son un objeto matemático formal que puede ser estudiado, aparecen
los \textit{sistemas de inferencia} o \textit{deductivos}: sistemas lógicos formales que
permiten demostrar sentencias. Nos son útiles pues pueden ser modelados como un
tipo abstracto de datos, por lo que son representables en la computadora.

Por ejemplo, supongamos que tenemos la siguiente \textit{teoría} sobre exámenes
en la facultad, que iremos iterando a lo largo de la tesis. Por ahora, en su
versión proposicional. Si un alumno reprueba un final, entonces recursa. Si un
alumno falta, entonces reprueba. Con estas dos, podríamos demostrar que si un
alumno falta a un final, entonces recursa. Veamos cómo podría ser una
demostración en lenguaje natural.

\begin{ejemplo}\label{nd:ex:exam}
    Si ((falta entonces reprueba) y (reprueba entonces recursa)) y falta, entonces recursa.

    Demostración:
\begin{itemize}
    \item Asumo que falta. Quiero ver que recursa.
    \item Sabemos que si falta, entonces reprueba. Por lo tanto reprobó.
    \item Sabemos que si reprueba, entonces recursa.
    \item Por lo tanto recursó. \qed
\end{itemize}
\end{ejemplo}

¿Cómo podrá ser formalizada en un \textit{sistema de inferencia}?

\section{El sistema de deducción natural}

Los sistemas de inferencia en general están compuestos por

\begin{itemize}
    \item \textbf{Lenguaje formal}: el conjunto $L$ de fórmulas admitidas por
    el sistema. En nuestro caso, lógica de primer orden.
    \item \textbf{Reglas de inferencia}: lista de reglas que se usan para probar
    teoremas de axiomas y otros teoremas. Por ejemplo, \textit{modus ponens} (si
    es cierto $\form \fImp \formTwo$ y $\form$, se puede concluir $\formTwo$) o
    \textit{modus tollens} (si es cierto $\form \fImp \formTwo$ y $\fNot
    \formTwo$, se puede concluir $\fNot\form$)
    \item \textbf{Axiomas}: fórmulas de $L$ que se asumen válidas. Todos los
    teoremas se derivan de axiomas. Por ejemplo, como usamos lógica clásica,
    vale el axioma \textit{LEM} (Law of Excluded Middle): $\form \vee \fNot \form$
\end{itemize}

El sistema particular que usamos se conoce como \textbf{deducción natural},
introducido por Gerhard Gentzen en \cite{gentzen-1935}. Tiene dos tipos de
\textit{reglas de inferencia} para cada conectivo ($\wedge$, $\vee$, $\exists$,
$\dots$) y cuantificador ($\forall$, $\exists$), que nos permite razonar de dos formas distintas.

\begin{itemize}
    \item \textbf{Regla de introducción}: ¿Cómo demuestro una fórmula formada por este conectivo?
    \item \textbf{Regla de eliminación}: ¿Cómo uso una fórmula formada por este conectivo para demostrar otra?
\end{itemize}

Por ejemplo, la regla \ruleAndI{} nos va a permitir \textit{introducir} una conjunción, demostrarla. \ruleOrE{} \textit{eliminar} una disyunción, usarla para demostrar otra fórmula. Primero vemos algunas definiciones preliminares, luego las reglas de inferencia, un ejemplo de una demostración, y finalmente explicamos cada regla en detalle.

\begin{definition}[Contexto de demostración]
    Definimos,
    \begin{itemize}
        \item Los \textbf{contextos de demostración} $\ctx$ como un conjunto de fórmulas, compuesto por las hipótesis que se asumen a lo largo de una demostración.
        \item \diffNew{Por practicidad, notamos la unión como}
        \[
            \ctx, \anyForm = \ctx \cup \{\anyForm\}
        \]
        \item Para algunas reglas es necesario conocer las variables libres de un contexto, que se definen de la forma esperable:
        \[
            \fv{\ctx} = \bigcup_{\form \in \ctx} \fv{\form}
        \]
    \end{itemize}
\end{definition}

\begin{definition}[\diffNew{Relación de consecuencia}]
    Las reglas de inferencia de la \namedref{nd:inference-rules} definen la relación de consecuencia $\judG$, que nos permite escribir \textit{juicios} $\ctx \judG \form$. Intuitivamente pueden ser interpretados como ``$\form$ es una consecuencia de las suposiciones de $\ctx$''

    Más precisamente, el juicio será cierto si en una cantidad finita de pasos
    podemos, a partir de las fórmulas de $\ctx$, los axiomas y las reglas de
    inferencia, concluir $\form$. En ese caso decimos que $\form$ es
    \textit{derivable} a partir de $\ctx$.
    
    Cuando el contexto es omitido, $\judG \form$ se usa como abreviación de
    $\emptyset \judG \form$.
\end{definition}

\begin{definition}[Sustitución]
    Notamos la \textbf{sustitución sin capturas} de todas las ocurrencias libres de la variable $\var$ por el término $\term$ en la fórmula $\form$ como

    \[
        \form \subst{\var}{\term}
    \]

    Se explora en más detalle en la \fullref{nd:sec:subst}
\end{definition}

\subsection{Reglas de inferencia}

\begin{figure}[H]
    \begin{multicols}{2}
        \proofTreeFalseE
        \proofTreeTrueI
    \end{multicols}
    
    \begin{multicols}{2}
        \proofTreeLEM
        \proofTreeAx
    \end{multicols}

    \proofSpacing

    \proofTreeAndI

    \begin{multicols}{2}
        \proofTreeAndEOne
        \proofTreeAndETwo
    \end{multicols}

    \proofSpacing

    \begin{multicols}{2}
        \proofTreeOrIOne
        \proofTreeOrITwo
    \end{multicols}
    
    \proofTreeOrE

    \proofSpacing

    \begin{multicols}{2}
        \proofTreeImpI
        \proofTreeImpE
    \end{multicols}
    \begin{multicols}{2}
        \proofTreeNotI
        \proofTreeNotE
    \end{multicols}

    \proofSpacing

    \begin{multicols}{2}
        \proofTreeForallI
        \proofTreeForallE
    \end{multicols}

    \proofSpacing

    \proofTreeExistsI
    \proofTreeExistsE

    \caption{Reglas de inferencia para deducción natural de lógica clásica de primer orden}
    \label{nd:inference-rules}
\end{figure}

\subsection{Ejemplo introductorio}

\begin{ejemplo}\label{nd:ex:exam-nd}
    Demostración de \namedref{nd:ex:exam} en deducción natural. Lo modelamos para un solo alumno y materia, sin cuantificadores. Notamos
    \begin{itemize}
        \item $\reprueba \equiv \predReprueba(juan, \funFinal(logica))$
        \item $\recursa \equiv \predRecursa(juan, logica)$
        \item $\falta \equiv \predFalta(juan, \funFinal(logica))$
    \end{itemize}

    Queremos probar entonces 
    \[
        \Big(
            (\reprueba \fImp \recursa) \wedge (\falta \fImp \reprueba)
        \Big)
        \fImp
        (\falta \fImp \recursa)
    \]

    \begin{figure}[H]
        \begin{prooftree}
            \AxiomC{}
            \RL{\ruleAx}
            \UnaryInfC{$\ctx \judG (\reprueba \fImp \recursa) \wedge (\falta \fImp \reprueba)$}
            \RL{\ruleAndEOne}
            \UnaryInfC{$\ctx \judG \reprueba \fImp \recursa$}
    
            \AxiomC{}
            \RL{\ruleAx}
            \UnaryInfC{$\ctx \judG (\reprueba \fImp \recursa) \wedge (\falta \fImp \reprueba)$}
            \RL{\ruleAndETwo}
            \UnaryInfC{$\ctx \judG \falta \fImp \reprueba$}
            \AxiomC{}
            \RL{\ruleAx}
            \UnaryInfC{$\ctx \judG \falta$}
            \RL{\ruleImpE}
            \BinaryInfC{$\ctx \judG \reprueba$}
            \RL{\ruleImpE}
            \BinaryInfC{\(
                \ctx =
                (\reprueba \fImp \recursa) \wedge (\falta \fImp \reprueba),\
                \falta
                \judG
                \recursa
            \)}
            \RL{\ruleImpI}
            \UnaryInfC{\(
                (\reprueba \fImp \recursa) \wedge (\falta \fImp \reprueba)
                \judG
                \falta \fImp \recursa 
            \)}
            \RL{\ruleImpI}
            \UnaryInfC{\(
                \judG
                \Big(
                    (\reprueba \fImp \recursa) \wedge (\falta \fImp \reprueba)
                \Big)
                \fImp
                (\falta \fImp \recursa)
            \)}
        \end{prooftree}
    
        \caption{Demostración de \(
        \big(
            (\reprueba \fImp \recursa) \wedge (\falta \fImp \reprueba)
        \big)
        \fImp
        (\falta \fImp \recursa)
    \) en deducción natural}
        \label{nd:fig:proof-exam-nd}
    \end{figure}

    Las demostraciones en deducción natural son un árbol, en el que cada juicio está justificado por una regla de inferencia, que puede tener sub-árboles de demostración. La raíz es la fórmula a demostrar. Paso por paso,

    \begin{itemize}
        \item \ruleImpI: \textit{introducimos} la implicación. Para demostrarla,
        asumimos el antecedente y en base a eso demostramos el consecuente. Es
        decir asumimos $(\reprueba \fImp \recursa) \wedge (\falta \fImp
        \reprueba)$, y en base a eso queremos deducir $\falta \fImp \recursa$.
        \item \ruleImpI: asumimos $\falta$, nos queda probar $\recursa$.
        Nombramos el \textit{contexto} de hipótesis como $\ctx$.
        \item La estrategia para probar $\recursa$ es usando la siguiente cadena
        de implicaciones: $\falta \fImp \reprueba \fImp \recursa$, y sabemos que
        vale $\falta$. Como tenemos que probar $\recursa$, vamos de derecha a izquierda.
        \item \ruleImpE: \textit{eliminamos} una implicación, la usamos para
        deducir su conclusión demostrando el antecedente. Esta regla de
        inferencia tiene dos partes, probar la implicación ($\reprueba \fImp
        \recursa$), y probar el antecedente ($\reprueba$).
        \begin{itemize}
            \item Para probar la implicación, tenemos que usar la hipótesis \textit{eliminando} la conjunción y especificando cuál
            de las dos cláusulas estamos usando.
            \item Para probar el antecedente $\reprueba$, es un proceso análogo
            pero usando la otra implicación y el hecho de que vale $\falta$ por hipótesis.
        \end{itemize}
        \item Las hojas del árbol, los casos base, suelen ser aplicaciones de
        la regla de inferencia \ruleAx, que permite deducir fórmulas citando
        hipótesis del contexto.
    \end{itemize}
\end{ejemplo}

\section{Intuición detrás de las reglas}

A continuación se explican brevemente las reglas de inferencia listadas en \namedref{nd:inference-rules}.

\subsection{Reglas base}

\begin{multicols}{2}
    \proofTreeFalseE
    \proofTreeTrueI
\end{multicols}

\begin{multicols}{2}
    \proofTreeLEM
    \proofTreeAx
\end{multicols}

\begin{itemize}
    \item \ruleFalseE: a partir de $\fFalse$, algo que es falso, vamos a poder deducir cualquier
    fórmula.
    \item \ruleTrueI: $\fTrue$ trivialmente vale siempre
    \item \ruleLEM: el \textit{principio del tercero excluido} que vale en
    lógica clásica. Incluir este axioma es lo que hace que este sistema sea
    clásico.
    \item \ruleAx: como ya vimos en el \fullref{nd:ex:exam-nd}, lo usamos para
    deducir fórmulas que ya tenemos como hipótesis.
\end{itemize}

\subsection{Reglas de conjunciones y disyunciones}

\proofTreeAndI

\begin{multicols}{2}
    \proofTreeAndEOne
    \proofTreeAndETwo
\end{multicols}

\begin{multicols}{2}
    \proofTreeOrIOne
    \proofTreeOrITwo
\end{multicols}

\proofTreeOrE

\begin{itemize}
    \item \ruleAndI: para demostrar una conjunción, debemos demostrar ambas fórmulas.
    \item \ruleAndEOne / \ruleAndETwo: a partir de una conjunción podemos
    deducir cualquiera de las dos fórmulas que la componen, porque ambas valen.
    Se modela con dos reglas.
    \item \ruleOrIOne / \ruleOrITwo: para demostrar una disyunción, alcanza con
    demostrar una de sus dos fórmulas. Se modela con dos reglas al igual que la
    eliminación de conjunción.
    \item \ruleOrE: nos permite deducir una conclusión a partir de una
    disyunción dando sub demostraciones que muestran que sin importar cual de
    las dos valga, asumiéndolas por separado, se puede demostrar.
\end{itemize}

\subsection{Reglas de implicación y negación}

\begin{multicols}{2}
    \proofTreeImpI
    \proofTreeImpE
\end{multicols}

\proofSpacing

\begin{multicols}{2}
    \proofTreeNotI
    \proofTreeNotE
\end{multicols}

\begin{itemize}
    \item \ruleImpI: para demostrar una implicación, asumimos el antecedente
    (agregándolo a las hipótesis) y en base a eso se demuestra el consecuente.
    \item \ruleImpE: también conocida como \textit{modus ponens}. A partir de
    una implicación, si podemos demostrar su antecedente, entonces vale su consecuente.
    \item \ruleNotI: para demostrar una negación, lo hacemos por el absurdo:
    asumimos que vale la fórmula y llegamos a una contradicción.
    \item \ruleNotE: podemos concluir un absurdo demostrando que vale una
    fórmula y su negación.
\end{itemize}

\subsection{Reglas de cuantificadores}

Las reglas de $\forall$ y $\exists$ se pueden ver como extensiones a las de
$\wedge$ y $\vee$. Un $\forall$ se puede pensar como una conjunción con un
elemento por cada uno del dominio sobre el cual se cuantifica, y análogamente un $\exists$ como una disyunción.

\begin{multicols}{2}
    \proofTreeForallI
    \proofTreeForallE
\end{multicols}

\begin{itemize}
    \item \ruleForallI: para demostrar un $\forall \var. \form$, quiero ver que sin importar el valor que tome $\var$ yo puedo demostrar $\form$. Pero para eso en el contexto $\ctx$ no tengo que tenerlo ligado a nada, sino no lo estaría demostrando en general.
    \item \ruleForallE: para usar un $\forall \var.\form$ para demostrar, como
    vale para todo $\var$, puedo instanciarlo en \textit{cualquier término} $\term$.
\end{itemize}

\proofTreeExistsI
\proofTreeExistsE

\begin{itemize}
    \item \ruleExistsI: para demostrar un $\exists$, alcanza con instanciar $\var$ en un término $\term$ para el que sea cierto.
    \item \ruleExistsE: para usar un $\exists$ para demostrar, es parecido a \ruleE{$\vee$}. Como tenemos que ver que vale para cualquier $\var$, podemos concluir $\formTwo$ tomando como hipótesis $\form$ con $\var$ sin instanciar. 
\end{itemize}

\begin{ejemplo}
    \label{nd:ex:exam-nd-lpo}
    Para ejemplificar el uso de las reglas de cuantificadores, extendemos el \namedref{nd:ex:exam-nd} para usar cuantificadores. Usamos

    \begin{itemize}
        \item Usamos las siguientes funciones 0-arias: $\vAlu$ representa un
        alumno, $\vMat$ una materia y $\vEx$ un examen.
        \item $\reprueba(\vAlu, \vEx) \equiv \predReprueba(\vAlu, \vEx)$
        \item $\recursa(\vAlu, \vMat) \equiv \predRecursa(\vAlu, \vMat)$
        \item $\falta(\vAlu, \vEx) \equiv \predFalta(\vAlu, \vEx)$
    \end{itemize}

    Vamos a tomar los siguientes como \textit{axiomas}, que van a formar parte del contexto inicial de la demostración. Es lo mismo que haremos en PPA al modelar teorías de primer orden.

    \begin{itemize}
        \item \textbf{Axioma 1}: si un alumno reprueba el final de una materia, entonces recursa
        \[
            \forall \vAlu .\ \forall \vMat .\
                (\reprueba(\vAlu, \funFinal(\vMat)) \fImp
                \recursa(\vAlu, \vMat))
        \]
        \item \textbf{Axioma 2}: si un alumno falta a un examen, lo reprueba
        \[
            \forall \vAlu .\ \forall \vEx .\
                (\falta(\vAlu, \vEx) \fImp \reprueba(\vAlu, \vEx))
        \]
    \end{itemize}

    Definimos

    \[
        \ctx_0 = \{
            \forall \vAlu .\ \forall \vMat .\
                \reprueba(\vAlu, \funFinal(\vMat)) \fImp
                \recursa(\vAlu, \vMat),
            \forall \vAlu .\ \forall \vEx .\
                \falta(\vAlu, \vEx) \fImp \reprueba(\vAlu, \vEx)
        \}
    \]

    Luego, queremos probar
    \(
        \ctx_0 \judG
            \forall \vAlu .\ \forall \vMat .\
                \falta(\vAlu, \funFinal(\vMat)) \fImp
                \recursa(\vAlu, \vMat)
    \)
    
    \begin{figure}
        \begin{prooftree}
            \AxiomC{}
            \RL{\ruleAx{}}
            \UnaryInfC{\(
                \ctx_1 \judG
                    \forall \vAlu \forall \vMat .\ \reprueba(\vAlu, \funFinal(\vMat)) \fImp \recursa(\vAlu, \vMat)
            \)}
            \RL{\ruleForallE{}}
            \UnaryInfC{\(
                \ctx_1 \judG
                    \forall \vMat .\ \reprueba(\vAlu, \funFinal(\vMat)) \fImp \recursa(\vAlu, \vMat)
            \)}
            \RL{\ruleForallE{}}
            \UnaryInfC{\(
                \ctx_1 \judG
                    \reprueba(\vAlu, \funFinal(\vMat)) \fImp \recursa(\vAlu, \vMat)
            \)}
    
            \AxiomC{$\someProof$}
            \noLine
            \UnaryInfC{\(
                \ctx_1 \judG \reprueba(\vAlu, \funFinal(\vMat))
            \)}
            \RL{\ruleImpE{}}
            \BinaryInfC{\(
                \ctx_1 = \ctx_0, \falta(\vAlu, \funFinal(\vMat)) \judG \recursa(\vAlu, \vMat)
            \)}
            \RL{\ruleImpI{}}
            \UnaryInfC{\(\ctx_0 \judG \falta(\vAlu, \funFinal(\vMat)) \fImp
                \recursa(\vAlu, \vMat)\)}
            \RL{\ruleForallI{}}
            \UnaryInfC{\(
                \ctx_0 \judG \forall \vMat .\
                \falta(\vAlu, \funFinal(\vMat)) \fImp
                \recursa(\vAlu, \vMat)
            \)}
            \RL{\ruleForallI{}}
            \UnaryInfC{\(
            \ctx_0 \judG
            \forall \vAlu .\ \forall \vMat .\
                \falta(\vAlu, \funFinal(\vMat)) \fImp
                \recursa(\vAlu, \vMat)
            \)}
        \end{prooftree}

        Con

        \begin{prooftree}
            \AxiomC{}
            \RL{\ruleAx}
            \UnaryInfC{\(
                \ctx_1 \judG
                    \forall \vAlu .\ \forall \vEx .\
                        \falta(\vAlu, \vEx) \fImp \reprueba(\vAlu, \vEx)
            \)}
            \RL{\ruleForallE{}}
            \UnaryInfC{\(
                \ctx_1 \judG
                    \forall \vEx .\
                        \falta(\vAlu, \vEx) \fImp \reprueba(\vAlu, \vEx)
            \)}
            \RL{\ruleForallE{}}
            \UnaryInfC{\(
                \ctx_1 \judG
                    \falta(\vAlu, \funFinal(\vMat)) \fImp \reprueba(\vAlu, \funFinal(\vMat))
            \)}
            \AxiomC{}
            \RL{\ruleAx{}}
            \UnaryInfC{\(
                \ctx_1 \judG \falta(\vAlu, \funFinal(\vMat))
            \)}
            \RL{\ruleImpE{}}
            \LL{$\someProof=$}
            \BinaryInfC{\(
                \ctx_1 \judG \reprueba(\vAlu, \funFinal(\vMat))
            \)}
        \end{prooftree}
        \caption{Demostración con cuantificadores en deducción natural}
    \end{figure}
\end{ejemplo}

\section{Ajustes para generación de demostraciones}

PPA genera demostraciones en deducción natural, pero no usa exactamente el sistema descrito en la \namedref{nd:inference-rules}, sino que tiene algunos ajustes.

\subsection{\diffNew{Hipótesis etiquetadas}}
\label{nd:sec:hyp-labels}

\diffNew{Sección re-redactada!}

En las secciones anteriores presentamos a los contextos $\ctx$ como \textit{conjuntos} de fórmulas. Pero en realidad vamos a querer que las hipótesis estén nombradas para proveer mayor claridad en las demostraciones. Para permitirlo, cada regla que introduce una hipótesis tiene que darle nombre, y cada regla que la usa, tiene que explicitar qué nombre tiene.

\begin{itemize}
    \item Los contextos $\ctx$ se redefinen como conjuntos de \textit{pares}
    $\hypId : \form$ de etiquetas y fórmulas.
    \item Las reglas que hacen uso de hipótesis, lo hacen nombrándolas.

    \begin{multicols}{3}
        \begin{prooftree}
            \AxiomC{$\bm{\hypId: } \form \in \ctx$}
            \RL{\ruleAxh{\bm{\hypId}}}
            \UnaryInfC{$\judg{\ctx}{\form}$}
        \end{prooftree}
    
        \begin{prooftree}
            \AxiomC{$\judg{\ctx, \bm{\hypId:} \form}{\formTwo}$}
            \RL{\ruleImpIh{\bm{\hypId}}}
            \UnaryInfC{$\judg{\ctx}{\form \to \formTwo}$}
        \end{prooftree}
    
        \begin{prooftree}
            \AxiomC{$\judg{\ctx, \bm{\hypId:} \form}{\bot}$}
            \RL{\ruleNotIh{\bm{\hypId}}}
            \UnaryInfC{$\judg{\ctx}{\fNot \form}$}
        \end{prooftree}
    \end{multicols}

    \begin{prooftree}
        \AxiomC{$\judg{\ctx}{\form \vee \formTwo}$}
        \AxiomC{$\judg{\ctx, \bm{\hypId_1:} \form}{\formThree}$}
        \AxiomC{$\judg{\ctx, \bm{\hypId_2:} \formTwo}{\formThree}$}
        \RL{\ruleOrEh{\bm{(\hypId_1, \hypId_2)}}}
        \TrinaryInfC{$\judg{\ctx}{\formThree}$}
    \end{prooftree}

    \begin{prooftree}
        \AxiomC{$\judg{\ctx}{\exists \var.\form}$}
        \AxiomC{$\judg{\ctx, \bm{\hypId:}\form}{\formTwo}$}
        \AxiomC{$x \notin \fv{\ctx, \formTwo}$}
        \RL{\ruleExistsEh{\bm{\hypId}}}
        \TrinaryInfC{$\judg{\ctx}{\formTwo}$}
    \end{prooftree}
\end{itemize}

\begin{notation*}
    Como abuso de notación, nos vamos a permitir la libertad de usar ambas versiones a lo largo del documento. En casos en donde no sea relevante usar etiquetas, no las usaremos, y en los casos en donde sí lo haremos explícitamente.
\end{notation*}

\begin{obs*}
    Las reglas están decoradas con el nombre de la hipótesis porque esto hace que según cual se use, el uso de la regla y por lo tanto la demostración sea diferente. Por lo que si por ejemplo demostramos $\form \fImp \form \fImp \form$, con etiquetas hay dos demostraciones distintas (dependiendo de si se usa la primera o segunda asunción) y sin habría una sola (como el contexto es un conjunto, se combinan ambas hipótesis en una).
\end{obs*}

\subsection{\diffNew{Variables libres en contexto}}
\diffNew{Re-redactado!}

Las reglas \ruleForallI{} y \ruleExistsE{} validan que la variable del cuantificador no esté libre en el contexto. Cuando sí aparece, el algoritmo de chequeo debe reportar un error. El usuario debería re-escribir la demostración para corregir el uso de variables evitando conflictos.

Pero esto representó un problema para la generación de demostraciones, pues se daban conflictos en casos inofensivos: si tenemos una demostración de un teorema que usa las variables $x, y$, y lo citamos en otro que también las usa, el conflicto sería accidental, no estamos queriendo razonar de forma inválida. Al chequear la demostración citada, ya se usaron las variables en el anterior, llevando a un error. Para evitarlo manteniendo las reglas como están, habría que renombrar con cuidado las variables de forma automática.

La reformulamos para evitarlo de una forma más simple: en lugar de validar que la variable no esté no esté, directamente se remueve del contexto todas las hipótesis que contengan libre esa variable en la sub-demostración. Cada sub-demostración tiene un contexto ``limpio``. Esto permite que si el conflicto era accidental, la demostración siga chequeando (porque no se usaban las hipótesis que generaban conflicto). Pero si se usaban, seguiría fallando pero con un error diferente (hipótesis inexistente).


Definimos
\[
    \ctx \ominus \var = \{ \form \in \ctx \mid \var \notin \fv{\form} \}
\]

Luego, las reglas son re-definidas como

\newcommand{\ctxClean}{\bm{\ctx \ominus \var}}

\begin{prooftree}
    \AxiomC{$\judg{\ctxClean}{\form}$}
    \RL{\ruleForallI}
    \UnaryInfC{$\judg{\ctx}{\forall \var.\form}$}
\end{prooftree}

\begin{prooftree}
    \AxiomC{$\judg{\ctxClean}{\exists \var.\form}$}
    \AxiomC{$\judg{\ctxClean, \hypId: \form}{\formTwo}$}
    \AxiomC{$x \notin \fv{\formTwo}$}
    \RL{\ruleExistsE$_\hypId$}
    \TrinaryInfC{$\judg{\ctx}{\formTwo}$}
\end{prooftree}

\nota{Lo re-redacté para dar un argumento un poco más robusto, si hace falta demostrar la inter-derivabilidad me decís y lo charlamos.}

\section{Reglas admisibles}\label{nd:sec:admissible-rules}

Antes mencionamos \textit{modus tollens} como regla de inferencia, pero no aparece en la \namedref{nd:inference-rules}. Esto es porque nos va a interesar tener un sistema
lógico minimal: no vamos a agregar reglas de inferencia que se puedan deducir a
partir de otras, es decir, \textit{reglas admisibles}. Nos va a servir para
simplificar el resto de PPA, dado que vamos a generar demostraciones en
deducción natural y operar sobre ellas. Mientras más sencillas sean las partes con las que se componen, mejor. Las reglas admisibles las podemos demostrar para cualquier fórmula, así luego podemos usarlas como \textit{macros}.

\begin{ejemplo}[\textit{Modus tollens}] Se puede demostrar como regla admisible.
    
    \begin{prooftree}
        \AxiomC{}
        \RL{\ruleAx}
        \UnaryInfC{\(\ctx \judG (\form \fImp \formTwo) \fAnd \fNot \formTwo\)}
        \RL{\ruleAndETwo}
        \UnaryInfC{\(
            \ctx \judG \fNot \formTwo
        \)}
        \AxiomC{}
        \RL{\ruleAx}
        \UnaryInfC{\(\ctx \judG (\form \fImp \formTwo) \fAnd \fNot \formTwo\)}
        \RL{\ruleAndEOne}
        \UnaryInfC{$\ctx \judG \form \fImp \formTwo$}
        \AxiomC{}
        \RL{\ruleAx}
        \UnaryInfC{$\ctx \judG \form$}
        \RL{\ruleImpE}
        \BinaryInfC{\(
            \ctx \judG \formTwo
        \)}
        \RL{\ruleNotE{}}
        \BinaryInfC{\(
            \ctx = (\form \fImp \formTwo) \fAnd \fNot \formTwo, \form
            \judG
            \fFalse
        \)}
        \RL{\ruleNotI{}}
        \UnaryInfC{\(
            (\form \fImp \formTwo) \fAnd \fNot \formTwo
            \judG
            \fNot \form
        \)}
        \RL{\ruleImpI{}}
        \UnaryInfC{\(\judG
            (\form \fImp \formTwo \fAnd \fNot \formTwo)
            \fImp \fNot\form
        \)}
    \end{prooftree}
\end{ejemplo}

\section{Algoritmos}

A continuación describimos los algoritmos que son necesarios para la implementación de deducción natural. El chequeo de las demostraciones, alfa equivalencia de fórmulas, sustitución sin capturas, y variables libres

\subsection{\diffNew{Chequeador}}
\label{nd:sec:checker}
\diffNew{Sección reescrita!}

El algoritmo de chequeo de una demostración en deducción natural consiste en recorrer recursivamente el árbol de demostración, asegurando que todas las inferencias sean válidas y manteniendo un contexto $\ctx$ en el camino.
Se chequea que cada regla se use con el conectivo que le corresponde (no un \ruleAndI{} para un $\fOr$) y que cumple con las condiciones impuestas.

El módulo que se encarga de implementarlo es el \modChecker, su función principal es

\begin{minted}{haskell}
    check :: Env -> Proof -> Form
\end{minted}

donde \mintinline{haskell}{Env} es el contexto $\ctx$, \mintinline{haskell}{Proof} es el término de demostración en deducción natural y \mintinline{haskell}{Form} es la fórmula que demuestra.

\subsection{Alfa equivalencia}

Si tenemos una hipótesis $\exists \var . \fun(\var)$, sería ideal poder usarla para demostrar a partir de ella una fórmula $\exists \varTwo . \fun(\varTwo)$. Si bien no son exactamente iguales, son \textbf{alfa-equivalentes}: su estructura es la misma, pero tienen nombres diferentes para variables \textit{ligadas} (no libres)

\begin{definition}[Alfa equivalencia] Se define la relación $\alphaEq$ como la que permite renombrar variables ligadas evitando capturas. Es la congruencia más chica que cumple con
\begin{align*}
    (\forall \var . \form) \alphaEq (\forall \varTwo . \form')
        &\iff
        \form \subst{\var}{\varThree} \alphaEq
        \form' \subst{\varTwo}{\varThree} \text{ con $\varThree$ fresca}
        \\
    (\exists \var . \form) \alphaEq (\exists \varTwo . \form')
        &\iff
        \form \subst{\var}{\varThree} \alphaEq
        \form' \subst{\varTwo}{\varThree} \text{ con $\varThree$ fresca}
        \\
\end{align*}
\end{definition}

Para implementarlo, un algoritmo naíf podría ser cuadrático: chequeamos recursivamente la igualdad estructural de ambas fórmulas. Si nos encontramos con un cuantificador con variables con nombres distintos, digamos $\var$ e $\varTwo$, elegimos una nueva variable \textit{fresca} (para evitar capturas) y lo renombramos recursivamente en ambos. Luego continuamos con el algoritmo. Si en la base nos encontramos con dos variables, tienen que ser iguales.

Para hacerlo un poco más eficiente, se implementó un algoritmo lineal en la estructura de la fórmula. Mantenemos dos sustituciones de variables, una para cada fórmula. Si nos encontramos con $\exists \var . \fun(\var)$ y $\exists \varTwo . \fun(\varTwo)$, vamos a elegir una variable fresca igual que antes (por ejemplo $\varThree$), pero en vez de renombrar recursivamente, que lo hace cuadrático, insertamos en cada sustitución los renombres $\var \mapsto \varThree$ y $\varTwo \mapsto \varThree$. Luego, cuando estemos comparando dos variables libres, chequeamos que \textit{sus renombres} sean iguales. En este ejemplo son alfa equivalentes, pues

\begin{align*}
    (\exists \var . \fun(\var)) \alphaEq (\exists \varTwo . \fun(\varTwo))
    &\iff \fun(\var) \alphaEq \fun(\varTwo)
        &&\{\var \mapsto \varThree\}, \{\varTwo \mapsto \varThree\}\\
    &\iff \var \alphaEq \varTwo
        &&\{\var \mapsto \varThree\}, \{\varTwo \mapsto \varThree\}\\
    &\iff \varThree = \varThree.
\end{align*}

\subsection{Sustitución sin capturas}\label{nd:sec:subst}

Notamos la sustitución de todas las ocurrencias libres de la variable $\var$ por un término $\term$ en una fórmula $\form$ como
\(
    \form\subst{\var}{\term}.
\)
Esto se usa en algunas reglas de inferencia,

\proofTreeForallE

Pero queremos evitar \textbf{captura de variables}. Por ejemplo, en

\[
    \forall \varTwo . \pred(\var)\subst{\var}{\varTwo},
\]

si sustituimos sin más, estaríamos involuntariamente ``capturando'' a $\varTwo$. Si hiciéramos que falle, tener que escribir las demostraciones con estos cuidados puede ser muy frágil y propenso a errores, por lo que es deseable que se resuelva \textit{automáticamente}: cuando nos encontramos con una captura, sustituimos la variable ligada de forma que no ocurra.

\[
    \forall \varTwo . \pred(\var)\subst{\var}{\varTwo} =
    \forall \bm{\varThree} . \pred(\varTwo)
\]

donde $\varThree$ es una variable \textit{fresca}.

\begin{definition}[\diffNew{Sustitución sin capturas}]
    \label{nd:def:subst}
    \diffNew{Corregido!}
    Se define por inducción estructural.
    \begin{itemize}
        \item Términos
        \begin{align*}
            \var\subst{\varTwo}{\term} &= \begin{cases}
                t &\text{si } \var = \varTwo\\
                \var &\text{si no}
            \end{cases}\\
            \fun(\term_1, \dots, \term_n)\subst{\varTwo}{\term} &=
                \fun(
                    \term_1\subst{\varTwo}{\term},
                    \dots,
                    \term_n\subst{\varTwo}{\term}
                )
        \end{align*}

        \item Fórmulas
        \begin{align*}    
            \fFalse\subst{\varTwo}{\term} &= \fFalse\\
            \fTrue\subst{\varTwo}{\term} &= \fTrue\\
            \pred(\term_1, \dots, \term_n)\subst{\varTwo}{\term} &=
            \pred(
                    \term_1\subst{\varTwo}{\term},
                    \dots,
                    \term_n\subst{\varTwo}{\term}
                )
            \\
            (\form \fAnd \formTwo)\subst{\varTwo}{\term} &= 
                \form\subst{\varTwo}{\term} \fAnd \formTwo\subst{\varTwo}{\term}\\
            (\form \fOr \formTwo)\subst{\varTwo}{\term} &=
            \form\subst{\varTwo}{\term} \fOr \formTwo\subst{\varTwo}{\term}\\
            (\form \fImp \formTwo)\subst{\varTwo}{\term} &=
            \form\subst{\varTwo}{\term} \fImp \formTwo\subst{\varTwo}{\term}\\
            (\fNot \form)\subst{\varTwo}{\term} &=
                \fNot \form\subst{\varTwo}{\term}\\
            (\forall \var . \form)\subst{\varTwo}{\term} &=
            \begin{cases}
                \forall \var . \form
                    &\text{si } \var = \varTwo\\
                \forall \varThree . (A\subst{\var}{\varThree})\subst{\varTwo}{\term}
                    &\text{si } \var \in \fv{\term} \text{, con } \varThree \text{ fresca}\\
                \forall \var . A\subst{\varTwo}{\term}
                    &\text{si no}
            \end{cases}
            \\
            (\exists \var . \form)\subst{\varTwo}{\term} &=
            \begin{cases}
                \exists \var . \form
                    &\text{si } \var = \varTwo\\
                \exists \varThree . (A\subst{\var}{\varThree})\subst{\varTwo}{\term}
                    &\text{si } \var \in \fv{\term} \text{, con } \varThree \text{ fresca}\\
                \exists \var . A\subst{\varTwo}{\term}
                    &\text{si no}
            \end{cases}
        \end{align*}

    \end{itemize}
\end{definition}

Para implementarlo, cada vez que nos encontramos con una captura, vamos a \textit{renombrar} la variable del cuantificador por una nueva, fresca. Al igual que la alfa igualdad, esto se puede implementar de forma naíf cuadrática pero lo hicimos lineal. Mantenemos un único mapeo a lo largo de la sustitución, y cada vez que nos encontramos con una variable libre, si son iguales la sustituimos por el término, y si está mapeada la renombramos.

\begin{definition}[Variables libres de una demostración] Sea $\someProof$ una demostración. $\fv{\someProof}$ son las variables libres de todas las fórmulas que la componen. Por ejemplo, para la siguiente

    \proofTreeAndI

    se tiene $\fv{\someProof} = \fv{\form} \cup \fv{\formTwo}$
    
\end{definition}
