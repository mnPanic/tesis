En este trabajo presentamos el lenguaje \ppaLang{} junto con los detalles de su
implementación en \ppaTool{}. Primero dimos una definición completa del sistema
lógico de deducción natural, junto con ejemplos de demostraciones. Describimos
cómo implementamos el algoritmo de chequeo, y por otro lado los de
alfa equivalencia y sustitución sin capturas en tiempo cuasilineal en peor caso.

Dimos un manual de usuario para el lenguaje \ppaLang{}, explicando como
escribir demostraciones y cómo usar el mecanismo de demostración principal
\lstinline{by}. Dimos una demostración completa que muestra diferentes capacidades del lenguaje. También se listaron
todos los comandos, ejemplos funcionales para cada uno, y su relación con las
reglas de inferencia de deducción natural. Profundizamos en la implementación
del certificador y cómo están implementadas cada una de las partes de la
interfaz. Centralmente el \textit{solver} usado por debajo del \lstinline{by}.

Finalmente vimos una implementación posible de extracción de testigos
existenciales. Mencionamos las limitaciones al tratar de hacerlo de forma
directa sobre lógica clásica, las distintas versiones de la traducción de
Friedman según el tipo de fórmula a demostrar, y las limitaciones que se
presentaron (no se podrá asumir cualquier axioma, ni demostrar cualquier fórmula
$\classPiTwo$). Luego describimos cómo a partir del isomorfismo Curry-Howard
pudimos implementar un mecanismo de normalización de demostraciones, que también
presentó limitaciones (no todas las demostraciones podrán ser llevadas a su
forma normal) y requirió cambios en la estrategia de reducción de una sencilla a
una más sofisticada (Gross-Knuth) debido al tamaño de las demostraciones.

El principal aporte del trabajo es la implementación práctica de un método de
extracción indirecto mediante el uso de la traducción de Friedman y la
normalización usual de la lógica intuicionista.

\section{Trabajo futuro}

Surgieron varias líneas de trabajo futuro, que quedaron fuera del alcance de la
tesis. Las listamos a continuación.

\begin{itemize}
    \item \textbf{Modelar de forma nativa inducción e igualdad}: las teorías que
    se pueden axiomatizar están limitadas al no poder representar inducción de
    forma nativa (como predica sobre predicados, es lógica de segundo orden). Si
    bien sí se puede axiomatizar de forma \textit{adhoc}, sería más amigable de
    estar como regla de inferencia y a lo largo de todo el programa. También se
    podría agregar de forma nativa la noción de \textit{igualdad}.
    \item \textbf{Sofisticar \textit{solver} del by}: en
    \fullref{ppa-cert:sec:expressiveness} se mencionan las limitaciones del
    \textit{solver} usado por el \lstinline{by}. Una funcionalidad que quedó
    afuera pero sería sencilla de agregar es que no solo se busque eliminar los
    $\forall$ consecutivos de \textit{una} hipótesis, sino que el proceso sea
    recursivo: que exhaustivamente intente de eliminar los $\forall$ de todas
    las combinaciones de hipótesis posibles.
    \item \textbf{Mejorar a PPA como lenguaje de programación}: el
    lenguaje PPA no brinda soporte para tener un ecosistema. Se pueden agregar
    muchas funcionalidades que mejorarían la calidad de vida del desarrollador
    como permitir importar archivos o módulos e implementar una biblioteca
    estándar de teorías y teoremas.
    \item \textbf{Extender PPA con tipos}: el lenguaje no permite ni especificar
    ni chequear tipos. Se podría implementar una versión tipada, basada en
    lógica de primer orden \textit{many sorted} (con varios géneros) que
    facilitaría la escritura de programas más sofisticados.
    \item \textbf{Refinar fórmulas \textit{conjuntivas}}: en la traducción de
    Friedman introducimos dos lemas centrales: $\formTwo \judgI \tdn{\formTwo}$
    \fullref{fri:lemma:trans-intro}, que vale para \textit{F-fórmulas}
    y restringe las axiomatizaciones, y $\fNotR
    \form \judgI \fNotR \tdn{\form}$ \fullref{fri:lemma:notr-trans-intro}, que
    vale para fórmulas \textit{conjuntivas}. Como el primero se reduce al
    segundo, podríamos refinar las fórmulas \textit{conjuntivas}, lo que
    permitiría usar más tipos de axiomas. También se podría profundizar en el
    vínculo con las fórmulas de Harrop mencionado en \namedref{fi:obs:harrop}.
    \item \textbf{Extender traducción de Friedman a más de un existencial}: en
    su versión final, lo máximo que llega a convertir son fórmulas de la forma
    $\forall \varTwo_1 \dots \forall \varTwo_n . \exists \var .
    \anyForm(\dots)$. Se debería poder extender a fórmulas de la forma $\forall
    \varTwo_1 \dots \forall \varTwo_n . \exists \var_1 \dots \exists \var_m .
    \anyForm(\dots)$.
    \item \textbf{Implementar versión completa de reducción de demostraciones}:
    en \fullref{fri:norm:sec:limitations} vimos las limitaciones del mecanismo
    de reducción implementado. Es ineficiente, y no se puede llegar a una forma
    normal útil para todas las demostraciones, evitando la extracción de
    testigos en casos donde debería ser posible. Se podrían extender para
    incluir reducciones permutativas e implementar una máquina abstracta para
    reducción \textit{call-by-need} o \textit{call-by-name}.
    \item \textbf{Mejorar reporte de errores}: los errores reportados por la
    herramienta en general son muy rústicos, implementativos y de bajo nivel. Se
    podrían hacer más amigables y accionables, ayudando a resolver problemas sin
    saber cómo funciona internamente la herramienta.
\end{itemize}